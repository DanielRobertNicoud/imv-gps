{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c391e89-3683-4e92-97e6-22c56689909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux_functions import *\n",
    "from sphere_vector_kernels import *\n",
    "from sphere_vector_gp import *\n",
    "from blender_file_generation import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import itertools as it\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import re\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, WhiteKernel, Matern, RBF, DotProduct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f743152-7a7f-4ca6-bbea-c05a3540caf6",
   "metadata": {},
   "source": [
    "### Read data\n",
    "\n",
    "Data is monthly averaged wind data at 500hP pressure level from January 2010 to December 2014. We will use each month as a separate experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f10dd-5f7c-43bf-a64d-79e07c56401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(\"era5\", \"monthly_averaged_wind_500hP.nc\")\n",
    "data = netCDF4.Dataset(fpath,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fb43e-4dd8-4752-8cdd-4ef2968c6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70848edc-a873-4ff9-bfda-10f2254618b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.variables['longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee354f1-51b8-44bc-b975-54dba02a5007",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_times = data.variables['time'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db82195-b2b3-43af-8ef6-87cc3371e2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = data.variables['longitude'][:].data\n",
    "lats = data.variables['latitude'][:].data\n",
    "lon_mesh, lat_mesh = np.meshgrid(lons, lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d104df-d540-4357-b190-07ff431575fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(time):\n",
    "    u = data.variables['u'][time].data\n",
    "    v = data.variables['v'][time].data\n",
    "    df = pd.DataFrame({\n",
    "        \"lon\": lon_mesh.flatten(),\n",
    "        \"lat\": lat_mesh.flatten(),\n",
    "        \"u\": u.flatten(),\n",
    "        \"v\": v.flatten(),\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7534cc0-87be-41da-b4ac-d33cba3a7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train sets: an \"orbit\" or some points around the sphere\n",
    "def orbit(df):\n",
    "    lats_train = lats[::40]\n",
    "    lons_train = np.array([90., 270.])\n",
    "    orbit = df.query(\"lat in @lats_train and lon in @lons_train\").reset_index(drop=True).copy()\n",
    "    return orbit\n",
    "\n",
    "def crystal(df):\n",
    "    lat_lons = { # lat => lons\n",
    "        -90: [0.],\n",
    "        -45: lons[::180],\n",
    "        0: lons[::90],\n",
    "        45: lons[::180],\n",
    "        90: [0.],\n",
    "    }\n",
    "    train_points = pd.concat([\n",
    "        df.query(f\"lat == @lat and lon in @lons\").copy()\n",
    "        for lat, lons in lat_lons.items()\n",
    "    ]).reset_index(drop=True)\n",
    "    return train_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ab973-7331-4349-90e0-de37212016c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_sets(time, train_set):\n",
    "    # read in data\n",
    "    df = read_data(time)\n",
    "    df_train = {\n",
    "        \"crystal\": crystal,\n",
    "        \"orbit\": orbit,\n",
    "    }[train_set](df)\n",
    "    df_test = test_set(df)\n",
    "    # X sets, degrees to radians\n",
    "    X_train, X_test = np.pi * df_train[[\"lat\", \"lon\"]].to_numpy() / 180, np.pi * df_test[[\"lat\", \"lon\"]].to_numpy() / 180\n",
    "    # y sets, normalization\n",
    "    y_train, y_test = df_train[[\"v\", \"u\"]].to_numpy(), df_test[[\"v\", \"u\"]].to_numpy()\n",
    "    norm_constant = jax.vmap(jnp.linalg.norm)(y_train).mean()\n",
    "    y_train /= norm_constant\n",
    "    y_test /= norm_constant\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d13cfc-7582-4438-a0ed-465693bb5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set: input locations for blender, matched to closest point in the data\n",
    "\n",
    "# for each of the inputs, match the closest point in the data\n",
    "\n",
    "blender_folder = \"blender-data\"\n",
    "out_folder = os.path.join(\"blender-data\", \"outputs\")\n",
    "\n",
    "mean_inputs = pd.read_csv(\n",
    "    os.path.join(blender_folder, \"input_locations.csv\"),\n",
    "    names=[\"x\", \"y\", \"z\"]\n",
    ").to_numpy()\n",
    "\n",
    "std_inputs = pd.read_csv(\n",
    "    os.path.join(blender_folder, \"std_inputs.csv\"),\n",
    "    names=[\"x\", \"y\", \"z\"]\n",
    ").to_numpy()\n",
    "\n",
    "all_points = sph_to_car(read_data(0)[[\"lat\", \"lon\"]].to_numpy() * np.pi / 180)\n",
    "\n",
    "@jax.jit\n",
    "def _match_point_idx(input_car, all_points):\n",
    "    idx = jnp.argmin(\n",
    "        jax.vmap(lambda a, b: jnp.linalg.norm(a - b), in_axes=(None, 0))(input_car, all_points)\n",
    "    )\n",
    "    return idx\n",
    "\n",
    "MATCH_IDXS = jax.vmap(_match_point_idx, in_axes=(0, None))(mean_inputs, all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753b52da-2f42-4d0a-8905-f4ff58678adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set(df):\n",
    "    test = df.iloc[MATCH_IDXS].copy()\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfc50e-cea1-40a6-815e-b786c4561d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_sets(time, train_set=\"orbit\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "q = ax.quiver(X_test[:, 1] * 180 / np.pi, X_test[:, 0] * 180 / np.pi, y_test[:, 1], y_test[:, 0], angles=\"uv\")\n",
    "q._init()\n",
    "ax.quiver(X_train[:, 1] * 180 / np.pi, X_train[:, 0] * 180 / np.pi, y_train[:, 1], y_train[:, 0], angles=\"uv\", scale=q.scale, color=\"r\")\n",
    "\n",
    "X_train_car, y_train_car = v_sph_to_car(X_train, y_train)\n",
    "X_test_car, y_test_car = v_sph_to_car(X_test, y_test)\n",
    "\n",
    "np.savetxt(os.path.join(out_folder, f\"ERA5_orbit_{time}__mercator__mean.csv\"), np.hstack([X_test_car, y_test_car]), delimiter=\",\")\n",
    "np.savetxt(os.path.join(out_folder, f\"ERA5_orbit_{time}__mercator__observations.csv\"), np.hstack([X_train_car, y_train_car]), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4b8f91-87d2-4ced-9dc6-b163b8c35e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_sets(time, train_set=\"crystal\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "q = ax.quiver(X_test[:, 1] * 180 / np.pi, X_test[:, 0] * 180 / np.pi, y_test[:, 1], y_test[:, 0], angles=\"uv\")\n",
    "q._init()\n",
    "ax.quiver(X_train[:, 1] * 180 / np.pi, X_train[:, 0] * 180 / np.pi, y_train[:, 1], y_train[:, 0], angles=\"uv\", scale=q.scale, color=\"r\")\n",
    "\n",
    "X_train_car, y_train_car = v_sph_to_car(X_train, y_train)\n",
    "X_test_car, y_test_car = v_sph_to_car(X_test, y_test)\n",
    "\n",
    "np.savetxt(os.path.join(out_folder, f\"ERA5_crystal_{time}__mercator__mean.csv\"), np.hstack([X_test_car, y_test_car]), delimiter=\",\")\n",
    "np.savetxt(os.path.join(out_folder, f\"ERA5_crystal_{time}__mercator__observations.csv\"), np.hstack([X_train_car, y_train_car]), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfec18b-9e84-41d2-af41-5332156c5df1",
   "metadata": {},
   "source": [
    "### Experiment utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8d46c-e25e-4072-912f-2b63e5268493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return jax.vmap(jax.jit(lambda a, b: jnp.linalg.norm(a - b)**2))(y_true, y_pred).mean()\n",
    "\n",
    "def pred_nll(y_true, y_pred, std_pred):\n",
    "    return -jax.vmap(jax.scipy.stats.multivariate_normal.logpdf)(y_true, y_pred, std_pred).mean()\n",
    "\n",
    "def run_single_experiment(X_train, y_train, X_test, y_test, model, number, verbose=True, n_restarts_optimizer=0):\n",
    "    name, k = model\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    gp = SphereVectorGP(kernel=k, n_restarts_optimizer=0)\n",
    "\n",
    "    gp.fit(X_train, y_train)\n",
    "    if verbose:\n",
    "        display(gp)\n",
    "        display(\"MLL:\", -gp.log_marginal_likelihood_value_ / X_train.shape[0])\n",
    "\n",
    "    mu_star, std = gp.predict(X_test, return_std=True)\n",
    "    metrics[\"name\"] = name\n",
    "    metrics[\"n\"] = number\n",
    "    metrics[\"fitted_gp\"] = str(gp)\n",
    "    metrics[\"MSE\"] = float(mse(y_test, mu_star))\n",
    "    metrics[\"PNLL\"] = float(pred_nll(y_test, mu_star, std))\n",
    "    if verbose:\n",
    "        display(metrics)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e42de-a915-4055-9333-a8d02625e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(models, train_test, fname, n_experiments=n_times, n_restarts_optimizer=0, verbose=False):\n",
    "    fpath = os.path.join(\"temp\", fname)\n",
    "    if os.path.exists(fpath):\n",
    "        with open(fpath, 'rb')as f:\n",
    "            results = pickle.load(f)\n",
    "    else:\n",
    "        results = {}\n",
    "    try:\n",
    "        for i, model in (pbar := tqdm(it.product(range(n_experiments), models), total=n_experiments * len(models))):\n",
    "            name = model[0]\n",
    "            if (i, name) in results:\n",
    "                continue\n",
    "            X_train, X_test, y_train, y_test = train_test(time=i)\n",
    "            results[(i, name)] = run_single_experiment(X_train, y_train, X_test, y_test, model, i, verbose=verbose, n_restarts_optimizer=n_restarts_optimizer)\n",
    "            with open(fpath, 'wb')as f:\n",
    "                pickle.dump(results, f)\n",
    "    finally:\n",
    "        return pd.DataFrame(results.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865e4385-3f66-4489-886d-a45b47ab4383",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ad8d9-0920-4462-b81c-5dce3b9f0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = [ # (base_name, base_kernel, args)\n",
    "    (r\"div-free H.--M.--$\\tfrac{1}{2}$\", HodgeMaternDivFreeSphereKernel, {\"nu\": 0.5}),\n",
    "    (r\"Proj.~M.--$\\tfrac{1}{2}$\", ProjectedMaternSphereKernel, {\"nu\": 0.5}),\n",
    "]\n",
    "\n",
    "models = [\n",
    "    (\"Pure noise\", WhiteKernel()),\n",
    "    (r\"Proj.\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * ProjectedSphereKernel(kappa=.2) + WhiteKernel()),\n",
    "    (r\"Hodge\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * HodgeSphereKernel(kappa=.2) + WhiteKernel()),\n",
    "    (r\"H.--M.--$\\tfrac{1}{2}$\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * HodgeMaternSphereKernel(kappa=.2, nu=0.5) + WhiteKernel()),\n",
    "    (r\"div-free Hodge\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * HodgeDivFreeSphereKernel(kappa=.2) + WhiteKernel()),\n",
    "    (r\"div+curl Hodge\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * HodgeDivFreeSphereKernel(kappa=.2)\n",
    "     + ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * HodgeCurlFreeSphereKernel(kappa=.2) + WhiteKernel()),\n",
    "    (r\"div+curl H.--M.--$\\tfrac{1}{2}$\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * HodgeMaternDivFreeSphereKernel(kappa=.2, nu=0.5)\n",
    "     + ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * HodgeMaternCurlFreeSphereKernel(kappa=.2, nu=0.5) + WhiteKernel()),\n",
    "]\n",
    "\n",
    "for base_name, base_kernel, kwargs in factory:\n",
    "    models += [\n",
    "        (base_name, ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * base_kernel(**kwargs) + WhiteKernel()),\n",
    "        (base_name + r\" $\\kappa=0.5$\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * base_kernel(kappa=.5, kappa_bounds=\"fixed\", **kwargs) + WhiteKernel()),\n",
    "        (base_name + r\" $\\kappa=1.0$\", ConstantKernel(constant_value_bounds=(1e-5, 1e8)) * base_kernel(kappa=1., kappa_bounds=\"fixed\", **kwargs) + WhiteKernel()),\n",
    "    ]\n",
    "\n",
    "models = [\n",
    "    (re.sub(\"\\.\\s\", \".~\", name), kernel) for name, kernel in models\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7420b62-b480-4c0a-8cde-3408f6c13ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_and_pnll_table(df, n_drop=0, tex_fname=None):\n",
    "    df = df.rename(columns={\"name\": \"Kernel\"})\n",
    "    results = {}\n",
    "    for col in [\"MSE\", \"PNLL\"]:\n",
    "        if n_drop > 0:\n",
    "            df_stats = df.groupby(\"Kernel\").apply(\n",
    "                lambda gp: gp.sort_values(col).iloc[:-n_drop]\n",
    "            ).reset_index(drop=True)\n",
    "        else:\n",
    "            df_stats = df.copy()\n",
    "        df_stats= df_stats[[\"Kernel\", col]].groupby(\"Kernel\")[col].describe()\n",
    "        df_stats = df_stats.reset_index(drop=False)\n",
    "        df_stats = df_stats.set_index(\"Kernel\")[[\"mean\", \"std\"]].rename(columns={\"mean\": \"Mean\", \"std\": \"Std\"})\n",
    "        df_stats = df_stats.round(2)\n",
    "        \n",
    "        df_stats.columns = pd.MultiIndex(\n",
    "            levels=[[col], [\"Mean\", \"Std\"]],\n",
    "            codes=[[0, 0], [0, 1]],\n",
    "            sortorder=None,\n",
    "            names=None, dtype=None, copy=False, name=None, verify_integrity=True)\n",
    "        \n",
    "        results[col] = df_stats\n",
    "        \n",
    "    results = results[\"MSE\"].join(results[\"PNLL\"])\n",
    "        \n",
    "    s = results.style.highlight_min(\n",
    "        axis=0, subset=[(\"MSE\", \"Mean\"), (\"PNLL\", \"Mean\")], props='font-weight:bold;'\n",
    "    )\n",
    "    s = s.format(precision=2)\n",
    "    \n",
    "    latex_table = s.to_latex(hrules=True)\n",
    "    latex_table = latex_table.replace(\"\\\\font-weightbold\", \"\\\\bf\")\n",
    "\n",
    "    if tex_fname is not None:\n",
    "        with open(os.path.join(\"tables\", f\"{tex_fname}.tex\"), \"w\") as f:\n",
    "            f.write(latex_table)\n",
    "\n",
    "    display(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c266b2-c22a-4460-ba7d-e9cb4a3dc049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_and_samples(kernel, time, train_set, kernel_name, n_samples=0):\n",
    "    out_folder = os.path.join(\"blender-data\", \"outputs\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_sets(time, train_set=train_set)\n",
    "    \n",
    "    # plot ground truth\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    ax.quiver(X_test[:, 1] * 180 / np.pi, X_test[:, 0] * 180 / np.pi, y_test[:, 1], y_test[:, 0], angles=\"uv\")\n",
    "    ax.set_title(\"Ground truth\")\n",
    "    plt.show()\n",
    "    \n",
    "    gp = SphereVectorGP(kernel=kernel)\n",
    "    gp.fit(X_train, y_train)\n",
    "    display(gp)\n",
    "    # mean\n",
    "    y_pred = gp.predict(X_test)\n",
    "    \n",
    "    _, y_pred_car = v_sph_to_car(X_test, y_pred)\n",
    "    np.savetxt(os.path.join(out_folder, f\"ERA5_{kernel_name}_{train_set}_{time}_pred__mercator__mean.csv\"), np.hstack([mean_inputs, y_pred_car]), delimiter=\",\")\n",
    "    \n",
    "    # display predicted mean\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "    ax.coastlines()\n",
    "    ax.quiver(X_test[:, 1] * 180 / np.pi, X_test[:, 0] * 180 / np.pi, y_pred[:, 1], y_pred[:, 0], angles=\"uv\")\n",
    "    ax.set_title(\"Mean\")\n",
    "    plt.show()\n",
    "    \n",
    "    # uncertainty\n",
    "    std_fname = os.path.join(out_folder, f\"ERA5_{kernel_name}_{train_set}_{time}_pred__mercator__std.csv\")\n",
    "    if not os.path.exists(std_fname):\n",
    "        std_inputs_sph = car_to_sph(std_inputs)\n",
    "        _, std = gp.predict(std_inputs_sph, return_std=True, verbose=True)\n",
    "        uncertainty = np.array([np.linalg.norm(cov) for cov in std])\n",
    "\n",
    "        np.savetxt(std_fname, uncertainty, delimiter=\",\")\n",
    "    \n",
    "    if n_samples > 0:\n",
    "        # samples\n",
    "        y_samples = gp.sample_y(X_test, n_samples=n_samples)\n",
    "        for i in range(y_samples.shape[2]):\n",
    "            sample = y_samples[:, :, i]\n",
    "            _, sample_car = v_sph_to_car(X_test, sample)\n",
    "\n",
    "            np.savetxt(os.path.join(out_folder, f\"ERA5_{kernel_name}_{train_set}_{time}_sample_{i}__mercator__mean.csv\"), np.hstack([mean_inputs, sample_car]), delimiter=\",\")\n",
    "\n",
    "            # display sample\n",
    "            fig, ax = plt.subplots()\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            ax.coastlines()\n",
    "            ax.quiver(X_test[:, 1] * 180 / np.pi, X_test[:, 0] * 180 / np.pi, sample[:, 1], sample[:, 0], angles=\"uv\")\n",
    "            ax.set_title(f\"Posterior sample {i + 1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0195cc92-edd8-44b5-a488-e423871e9ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _params(s):\n",
    "    r_const = r\"([\\d\\.]+e*\\+*-*\\d*)\\*\\*2\"\n",
    "    r_kappa = r\"kappa=([\\d\\.]+e*\\+*-*\\d*)\"\n",
    "    r_noise = r\"noise_level=([\\d\\.]+e*\\+*-*\\d*)\"\n",
    "    r_nu = r\"nu=([\\d\\.]+e*\\+*-*\\d*)\"\n",
    "    \n",
    "    m_const = re.search(r_const, s)\n",
    "    m_kappa = re.search(r_kappa, s)\n",
    "    m_noise = re.search(r_noise, s)\n",
    "    m_nu = re.search(r_nu, s)\n",
    "    return pd.Series({\n",
    "        \"constant\": float(m_const.groups()[0])**2 if m_const is not None else np.NaN,\n",
    "        \"kappa\": float(m_kappa.groups()[0]) if m_kappa is not None else np.NaN,\n",
    "        \"nu\": float(m_nu.groups()[0]) if m_nu is not None else np.NaN,\n",
    "        \"noise_level\": float(m_noise.groups()[0]) if m_noise is not None else np.NaN,\n",
    "    })\n",
    "\n",
    "def extract_parameters(df):\n",
    "    df = df.copy()\n",
    "    df[[\"constant\", \"kappa\", \"nu\", \"noise_level\"]] = df.fitted_gp.apply(_params)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1414a5d-fd81-4a4a-a2c1-9b236791ff77",
   "metadata": {},
   "source": [
    "# Train on orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6c1ba-91cd-4465-a90f-02b369d7fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orbit = run_experiments(\n",
    "    models=models,\n",
    "    train_test=lambda time: train_test_sets(time, train_set=\"orbit\"),\n",
    "    fname=\"clean_era5_orbit.pickle\",\n",
    "    n_experiments=12,\n",
    "    n_restarts_optimizer=0,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670c6e1-ab9e-429a-938a-4084366fce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orbit = df_orbit.query(f\"name in {[name for name, _ in models]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73a35c-6552-4b71-841c-0a5694564445",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_orbit_experiment = df_orbit.query(\"not name.str.contains('kappa')\").copy()\n",
    "further_orbit_experiments = df_orbit.query(\"name.str.contains('kappa')\").copy()\n",
    "further_orbit_experiments[\"name\"] = further_orbit_experiments[\"name\"].apply(\n",
    "    lambda s: (\"H.--M. \" if s.startswith(\"d\") else \"Proj.~M. \") + s.split(\" \")[-1]\n",
    ")\n",
    "\n",
    "mse_and_pnll_table(original_orbit_experiment, n_drop=0, tex_fname=\"era5_orbit\")\n",
    "mse_and_pnll_table(further_orbit_experiments, n_drop=0, tex_fname=\"era5_orbit_fixed_kappa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6be8212-7be0-4008-bf29-304031834026",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(original_orbit_experiment.query(\"fitted_gp.str.contains('HodgeMaternDiv')\").fitted_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b80e52-3265-4c15-bda6-7839f4c40371",
   "metadata": {},
   "source": [
    "### Study parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b88bd18-92b7-43dc-b065-c0a379a92b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _single_kernel_param(k):\n",
    "    # regex\n",
    "    r_const = r\"([\\d\\.]+e*\\+*-*\\d*)\\*\\*2\"\n",
    "    r_kappa = r\"kappa=([\\d\\.]+e*\\+*-*\\d*)\"\n",
    "    r_noise = r\"noise_level=([\\d\\.]+e*\\+*-*\\d*)\"\n",
    "    r_nu = r\"nu=([\\d\\.]+e*\\+*-*\\d*)\"\n",
    "    \n",
    "    m_const = re.search(r_const, k)\n",
    "    m_kappa = re.search(r_kappa, k)\n",
    "    m_noise = re.search(r_noise, k)\n",
    "    m_nu = re.search(r_nu, k)\n",
    "    \n",
    "    noise_sigma = float(m_noise.groups()[0]) if m_noise else None\n",
    "    kappa = float(m_kappa.groups()[0]) if m_kappa else None\n",
    "    constant = float(m_const.groups()[0])**2 if m_const else None\n",
    "    nu = float(m_nu.groups()[0]) if m_nu else None\n",
    "    \n",
    "    # white noise\n",
    "    if \"WhiteKernel\" in k:\n",
    "        return {\"noise_sigma\": noise_sigma}\n",
    "    elif \"ProjectedSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = ProjectedSphereKernel(kappa=kappa)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"p_sigma\": np.sqrt(sigma_squared), \"p_kappa\": kappa}\n",
    "    elif \"ProjectedMaternSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = ProjectedMaternSphereKernel(kappa=kappa, nu=nu)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"pm_sigma\": np.sqrt(sigma_squared), \"pm_kappa\": kappa, \"pm_nu\": nu}\n",
    "    elif \"HodgeSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = HodgeSphereKernel(kappa=kappa)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"h_sigma\": np.sqrt(sigma_squared), \"h_kappa\": kappa}\n",
    "    elif \"HodgeMaternSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = HodgeMaternSphereKernel(kappa=kappa, nu=nu)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"hm_sigma\": np.sqrt(sigma_squared), \"hm_kappa\": kappa, \"hm_nu\": nu}\n",
    "    elif \"HodgeDivFreeSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = HodgeDivFreeSphereKernel(kappa=kappa)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"hdf_sigma\": np.sqrt(sigma_squared), \"hdf_kappa\": kappa}\n",
    "    elif \"HodgeMaternDivFreeSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = HodgeMaternDivFreeSphereKernel(kappa=kappa, nu=nu)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"hmdf_sigma\": np.sqrt(sigma_squared), \"hmdf_kappa\": kappa, \"hmdf_nu\": nu}\n",
    "    elif \"HodgeCurlFreeSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = HodgeCurlFreeSphereKernel(kappa=kappa)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"hcf_sigma\": np.sqrt(sigma_squared), \"hcf_kappa\": kappa}\n",
    "    elif \"HodgeMaternCurlFreeSphereKernel\" in k:\n",
    "        # normalization\n",
    "        kernel = HodgeMaternCurlFreeSphereKernel(kappa=kappa, nu=nu)\n",
    "        norm_const = np.trace(kernel(np.array([0., 0.])))\n",
    "        sigma_squared = constant * norm_const\n",
    "        return {\"hmcf_sigma\": np.sqrt(sigma_squared), \"hmcf_kappa\": kappa, \"hmcf_nu\": nu}\n",
    "    else:\n",
    "        raise NotImplementedError(k)\n",
    "\n",
    "def _params(s):\n",
    "    parameters = {}\n",
    "    # get kernel string\n",
    "    s = re.search(r\"SphereVectorGP\\((.*)\\)\", s).groups()[0]\n",
    "    for k in s.split(\" + \"):\n",
    "        parameters.update(_single_kernel_param(k))\n",
    "    parameters = pd.Series(parameters)\n",
    "    return parameters\n",
    "    \n",
    "\n",
    "def extract_parameters(df):\n",
    "    df = df.copy()\n",
    "    df = pd.concat([df, df.fitted_gp.apply(_params)], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618503b-29ea-4b72-9a67-33ef206a38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = extract_parameters(df_orbit)\n",
    "parameters = parameters\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8a203-cdd1-4e55-ae98-b21f425b36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 100 , 'display.max_columns', 20):\n",
    "    display(\n",
    "        parameters\n",
    "        .sort_values([\"n\", \"name\"])\n",
    "        .query(\"name.str.contains('div-free') and not name.str.contains('kappa')\")\n",
    "        # .query(\"name.str.contains('M.')\")\n",
    "        .dropna(how='all', axis=1)\n",
    "        .round(3)\n",
    "        .astype(str)\n",
    "        .replace(\"nan\", \"\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9416dcf-0277-45f5-befe-2c7c17a85e6f",
   "metadata": {},
   "source": [
    "### Generate some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01351b20-759f-4d32-abe8-21ee85dc4356",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_and_samples(\n",
    "    kernel=ConstantKernel(1.**2, constant_value_bounds=(1e-5, 1e8)) * HodgeMaternDivFreeSphereKernel(kappa=.5, nu=.5, kappa_bounds=\"fixed\") + WhiteKernel(),\n",
    "    time=0, train_set=\"orbit\", kernel_name=\"dfhm12_kappa=0.5\", n_samples=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4bb480-ff28-41d2-a42a-6a9beeb9410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_and_samples(\n",
    "    kernel=ConstantKernel(1.**2, constant_value_bounds=(1e-5, 1e8)) * ProjectedMaternSphereKernel(kappa=.5, nu=.5, kappa_bounds=\"fixed\") + WhiteKernel(),\n",
    "    time=0, train_set=\"orbit\", kernel_name=\"projm12_kappa=0.5\", n_samples=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
